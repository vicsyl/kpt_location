# maybe put under ds preparation?

# dataset:
dataset:

    # transforms
    reflection: null
    to_grey_scale: True

    # output
    write_metadata: True
    write_data: True
    write_imgs: True
    write_other: True

    # wandb
    tags: ["ds-colab"]
    wandb_run_name_keys: ["no_key_detector", "magic_items", "integer_scale", "reflection"]

    # ds
    augment: lazy # eager, lazy, null
    in_dirs: ["./dataset/raw_data"]
    keys: [""]
    # TODO automate this, too
    out_dir: "./dataset/a_SUPERPOINT_test_"
    max_files: null
    ends_with: '.tonemap.jpg'
    clean_out_dir: True

    # detection
    detector: SUPERPOINT # SIFT, SUPERPOINT, SIFT_KORNIA case-insensitive
    scale_ratio_th: null # for superpoint
    min_scale_th: 0.0 # for superpoint
    # scale_ratio_th > 1, scale_ratio \in [1 / scale_ratio_th, scale_ratio_th]
    #scale_ratio_th: 1.1
    #min_scale_th: 15.0
    #min_scale_th: 30.0
    err_th: 5.0
    down_scale: 0.3
    const_patch_size: 33

    # show
    show_kpt_patches: False
    compare_patches: False

    # irrelevant, only defaults
    half_pixel_adjusted: False
    integer_scale: True # try to scale so that the new size is exactly an integer
    dynamic_resizing: False # not for superpoint

    filtering:
        entries: 100
        max_error_distance: 0.071
        sort_error: null # max, null
        heatmap_or_img: both # heatmap, img, both, or null BUT relevant only to SuperPoint
        train_crop: null

train:

    # learning
    module: zero_inference # resnet_based
    accelerator: 'gpu' # ("cpu", "gpu", "tpu", "ipu", "hpu", "mps, "auto")
    gpus: [0]
    batch_size: 64
    max_epochs: 10
    learning_rate: 0.001
    freeze_feature_extractor: False
    scale_error: 1000
    log_every_n_entries: 1024

    # ds
    dataset_splits: 2 # 2 = train, validate, (4 = + test, predict)

    # wandb
    enable_wandlog: True # TODO use for ds as well
    tags: [ "train-colab" ]
    wandb_run_name_keys: [ "magic_out_dir",
                           "train.freeze_feature_extractor",
                           #"train.scale_error",
                           "train.module",
                           "dataset.filtering.entries",
                           "dataset.filtering.heatmap_or_img",
                           "dataset.filtering.train_crop",
                           "dataset.filtering.max_error_distance",
    ]

    # irrelevant, only defaults
    grouped_by_sizes: False
