# maybe put under ds preparation?

# dataset:
dataset:

    reflection: null
    write_data: True
    wandb_tags_keys: ["no_key_detector", "magic_items", "integer_scale", "reflection"]

    detector: SIFT # SIFT, SUPERPOINT, case-insensitive
    # scale_ratio_th > 1, scale_ratio \in [1 / scale_ratio_th, scale_ratio_th]
    scale_ratio_th: 1.1
    #scale_ratio_th: null # for superpoint
    min_scale_th: 15.0
    #min_scale_th: 30.0
    # min_scale_th: 0.0 # for superpoint

    err_th: 0.6

    down_scale: 0.3
    in_dirs: ["./dataset/raw_data"]
    keys: [""]

    #out_dir: "./dataset/var_sizes"
    #const_patch_size: null
    out_dir: "./dataset/sift_not_int_"
    const_patch_size: 33

    max_items: null
    #ends_with: '.jpg'
    ends_with: '.tonemap.jpg'
    clean_out_dir: False
    to_grey_scale: True

    # TODO another scenario: move to training - i.e. just normalize to zero mean
    half_pixel_adjusted: False
    show_kpt_patches: False
    compare_patches: False
    integer_scale: False # try to scale so that the new size is exactly an integer
    dynamic_resizing: False # not for superpoint

train:
    # ("cpu", "gpu", "tpu", "ipu", "hpu", "mps, "auto")
    accelerator: 'cpu'
    gpus: [0]
    batch_size: 32
    grouped_by_sizes: False
    max_epochs: 1
    learning_rate: 0.01
    enable_wandlog: False
    freeze_feature_extractor: False
    dataset_splits: 2 # 2 = train, validate, (4 = + test, predict)
